{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "W1_val = np.random.rand(4, 3)\n",
    "b1_val = np.random.rand(4, 1)\n",
    "W2_val = np.random.rand(1, 4)\n",
    "b2_val = np.random.rand(1, 1)\n",
    "x_val = np.random.rand(3, 1)\n",
    "\n",
    "W1 = tf.constant(W1_val)\n",
    "b1 = tf.constant(b1_val)\n",
    "W2 = tf.constant(W2_val)\n",
    "b2 = tf.constant(b2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=(3,1), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = (W1@x+b1)\n",
    "a1 = z1**2\n",
    "\n",
    "z2 = W2@a1 + b2\n",
    "a2 = z2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[ 6962.19332554],\n",
       "         [ 9821.4284842 ],\n",
       "         [10552.23930613]])], [array([[[[12148.65451011],\n",
       "           [17211.56717148],\n",
       "           [18415.60424182]]],\n",
       "  \n",
       "  \n",
       "         [[[17211.56717148],\n",
       "           [25168.80037002],\n",
       "           [26476.97723468]]],\n",
       "  \n",
       "  \n",
       "         [[[18415.60424182],\n",
       "           [26476.97723468],\n",
       "           [28287.02854993]]]])]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = x\n",
    "grads = tf.gradients(a2**2, var)\n",
    "hess = tf.hessians(a2**2, var)\n",
    "sess.run([grads, hess], feed_dict={x:x_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=() dtype=float64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd order derivative\n",
    "\n",
    "Our model starts with a vector valued input $\\vec{x}$, maps it to some intermediate value $\\vec{a}$ and finally produces a scalar y. The information flow looks like this:\n",
    "$$\n",
    "\\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_n \\end{bmatrix} \\to \n",
    "\\begin{bmatrix}a_1 \\\\ a_2 \\\\ \\vdots \\\\a_n \\end{bmatrix} \\to \n",
    "y\n",
    "$$\n",
    "\n",
    "We are interested in the first and second derivatives of y with respect to x. Since y is a scalar, the Jacobian matrix is a row vector, and the second derivative can be expressed as a Hessian: \n",
    "$$\n",
    "J_{yx}, (J_{yx})_i= \\frac{\\partial y}{\\partial x_i}\\\\\n",
    "H_{yx}, (H_{yx})_{ij} = \\frac{\\partial^2y}{\\partial x_i \\partial x_j}\n",
    "$$\n",
    "\n",
    "The first and second derivative of y with respect to a are given. The naming scheme is the same, we use $J_{ya}$ and $H_{ya}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use this to calculate $J_{yx}$ and $H_{yx}$.\n",
    "\n",
    "The Jacobian of y with respect to x is straightforward. First we calculate the Jacobian $J_{ax}$, since a is a vector, this is a matrix. To get the Jacobian $J_{yx}$, we use a matrix product:\n",
    "$$\n",
    "(J_{ax})_{ij} = \\frac{\\partial a_i}{\\partial x_j} \\\\\n",
    "(J_{yx})_{j} = \\sum_i (J_{ya})_i * (J_{ax})_{ij}\n",
    "$$\n",
    "\n",
    "The Hessian of y with respect to x is complicated. We need to look at all the paths through a, to compute the derivatives:\n",
    "$$\n",
    "\\begin{align}\n",
    "(H_{yx})_{ij}&= \\frac{\\partial^2 y}{\\partial x_i \\partial x_j} \\\\\n",
    "&= \\sum_{h,k} \\frac{\\partial^2 y}{\\partial a_h \\partial a_k} \\frac{\\partial a_h}{\\partial x_i} \\frac{\\partial a_k}{\\partial x_j} \\\\\n",
    "&\\; +\\sum_h \\frac{\\partial y}{\\partial a_h} \\frac{\\partial^2 a_h}{\\partial x_i \\partial x_j}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the Hessian consists of two components:\n",
    "$$\n",
    "\\begin{align}\n",
    "(H_{yx})_{ij} &= (I_{yx})_{ij} + (O_{yx})_{ij} \\\\\n",
    "(I_{yx})_{ij} &= \\sum_{h,k} \\frac{\\partial^2 y}{\\partial a_h \\partial a_k} \\frac{\\partial a_h}{\\partial x_i} \\frac{\\partial a_k}{\\partial x_j} \\\\\n",
    "(O_{yx})_{ij} &=\\sum_h \\frac{\\partial y}{\\partial a_h} \\frac{\\partial^2 a_h}{\\partial x_i \\partial x_j}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite this in terms of the given Jacobians and Hessians:\n",
    "$$\n",
    "\\begin{align}\n",
    "(I_{yx})_{i,j} &= \\sum_{h,k} (H_{ya})_{h,k} (J_{ax})_{h,i} (J_{ax})_{k,j} \\\\\n",
    "(O_{yx})_{i,j} &= \\sum_{h} (J_{ya})_{1, h} (H_{ax})_{h,i,j}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Please note the Hessian $H_{ax}$, this is indexed with 3 indices. Because a is a vector and we take the second derivative with respect to a vector, this becomes a 3-dimensional tensor. To avoid confusion, I'm using two indices for $(J_{ya})_{1, h}$, this is a row vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coding samples\n",
    "Now I will look at concerete implementations. To stay compatible with the notation above, I assume that our layer maps x to a and that the whole model finally outputs y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer():\n",
    "    def __init__(W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.J_y={}\n",
    "        self.H_y={}\n",
    "        \n",
    "    def forward(x):\n",
    "        self.x = x\n",
    "        self.a = W@x + b\n",
    "        return self.a\n",
    "    \n",
    "    def backward(J_ya):\n",
    "        self.J_ya = J_ya\n",
    "\n",
    "        # update the first derivatives of our params\n",
    "        self.J_y[\"W\"][:] = np.dot(dy_dout, self.inp.T)\n",
    "        self.J_y[\"b\"][:] = np.sum(dy_dout, keepdims=True, axis=1)\n",
    "\n",
    "        self.J_ax = self.W.T\n",
    "        self.J_yx = J_ya @ self.J_ax\n",
    "\n",
    "        return self.J_yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
